{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Evaluation by Direct Solution of Bellman Equation.\n",
    "\n",
    "Let us consider an Agent that has to navigate a Grid World with 12 states as shown below. The Agent starts from the bottom left and has to reach the top right corner without stepping on the column with negative reward. If the Agent falls into the shaded state it will bounce back to the previous state.<br>\n",
    "\n",
    "![title](gridworld.png)\n",
    "\n",
    " At any moment, Agent can take four actions - Up(^), Left(<), Down(V),right(>). <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "T = np.load(\"./T.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume that a Transition Model is given to the System. Below, we examine the Transition Probabilities of some states.<br>\n",
    " \n",
    " From the Terminal State (3), it does not move anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[3,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition Probability of Terminal State is made to be zero for all actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can examine that the Agent moves to the intended state with 0.8 Probability and moves to random direction with 0.1 probability. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0.8, 0. , 0. , 0. , 0.1, 0.1, 0. , 0. , 0. , 0. ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[6,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1, 0. , 0. , 0.8, 0. ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[6,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_policy_evaluation_linalg(p, r, T, gamma):\n",
    "    \"Solving the Bellman Equation directly\"\n",
    "    u = np.zeros(12)\n",
    "    for s in range(12):\n",
    "        if not np.isnan(p[s]):\n",
    "            action = int(p[s])\n",
    "            u[s] = np.linalg.solve(np.identity(12) - gamma*T[:,:,action], r)[s]\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2\n",
      "Gamma: 0.999\n",
      "Epsilon: 0.0001\n",
      "===================================================\n",
      "Estimated value function\n",
      "[-39.53391727 -35.80058996   0.7433094    1.        ]\n",
      "[ -0.63691929   0.         -40.          -1.        ]\n",
      "[-40.          -1.14877472  -1.37568607 -40.        ]\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.999\n",
    "iteration = 0\n",
    "\n",
    "#Generate the first policy randomly\n",
    "# Nan=Nothing, -1=Terminal, 0=Up, 1=Left, 2=Down, 3=Right\n",
    "p = np.random.randint(0, 4, size=(12)).astype(np.float32)\n",
    "p[5] = np.NaN\n",
    "p[3] = p[7] = -1 #terminal states\n",
    "\n",
    "#Value function initialised to zero\n",
    "v = np.array([0.0, 0.0, 0.0,  0.0,\n",
    "               0.0, 0.0, 0.0,  0.0,\n",
    "               0.0, 0.0, 0.0,  0.0])\n",
    "\n",
    "#let us assign appropriate rewards\n",
    "r = np.array([-0.04, -0.04, -0.04,  +1.0,\n",
    "              -0.04,   0.0, -0.04,  -1.0,\n",
    "              -0.04, -0.04, -0.04, -0.04])\n",
    "unchanged = False\n",
    "while True:\n",
    "    iteration += 1\n",
    "    epsilon = 0.0001\n",
    "    #1- Policy Evaluation\n",
    "    v1 = v.copy()\n",
    "    #Direct solution\n",
    "    v = return_policy_evaluation_linalg(p, r, T, gamma)\n",
    "    \n",
    "    \n",
    "    #Stopping criteria\n",
    "    delta = np.absolute(v - v1).max()\n",
    "    if (delta < epsilon * (1 - gamma) / gamma) or iteration > 100: \n",
    "        unchanged = True\n",
    "        break\n",
    " \n",
    "\n",
    "    if unchanged: break\n",
    "\n",
    "\n",
    "print(\"Iterations: \" + str(iteration))\n",
    "\n",
    "print(\"Gamma: \" + str(gamma))\n",
    "print(\"Epsilon: \" + str(epsilon))\n",
    "print(\"===================================================\")\n",
    "print(\"Estimated value function\")\n",
    "print(v[0:4])\n",
    "print(v[4:8])\n",
    "print(v[8:12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
